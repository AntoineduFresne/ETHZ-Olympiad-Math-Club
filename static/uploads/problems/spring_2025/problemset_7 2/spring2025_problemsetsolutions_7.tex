\documentclass[11pt, a4paper, oneside]{article}

% ===== Page Layout =====
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\usepackage{microtype}  % Improved text justification

% ===== Fonts & Encoding =====
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{lmodern}

% ===== Math Packages =====
\usepackage{amsmath, amssymb, amsthm}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{bbm}
\usepackage{tensor}
\usepackage{mathtools}

% ===== Graphics & Diagrams =====
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}
\usepackage{pst-node}

% ===== Bibliography =====
\usepackage{biblatex}
\addbibresource{references.bib}  % Uncomment and add your .bib file

% ===== Tables =====
\usepackage{makecell}

% ===== Colors =====
\usepackage{xcolor}
\definecolor{linkcolour}{rgb}{0.5,0,0}  % Dark red color for links

% ===== Hyperlinks =====
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    breaklinks,
    urlcolor=linkcolour, 
    linkcolor=linkcolour,
    citecolor=linkcolour
}

% ===== Custom Commands =====
\newcommand{\problem}[1][]{\section{#1} \hfill \par}
\newcommand{\solution}[1][]{\subsection*{#1}\hfill \par}

% ===== Theorem Environments =====
\newtheorem{theorem}{Theorem}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\theoremstyle{lemma}
\newtheorem*{lemma}{Lemma}

% ===== Text Highlighting =====
\usepackage{soul}
\newcommand\ba[1]{\setbox0=\hbox{$#1$}%
\rlap{\raisebox{.45\ht0}{\textcolor{linkcolour}{\rule{\wd0}{1pt}}}}#1} 
\def\bc#1{\textcolor{linkcolour}{BC note: {#1}}}
\def\b#1{\textcolor{linkcolour}{{#1}}}

% ===== Comment Environment =====
\usepackage{comment}
\begin{comment}
Useful LaTeX fonts:
\usepackage{mathptmx}
\usepackage{txfonts}
\usepackage{pxfonts}
\usepackage{mathpazo}
\usepackage{mathpple}
\usepackage{kmath,kerkis}
\usepackage{kurier}
\usepackage{arev}
\usepackage{euler}
\usepackage{eulervm}
\end{comment}

\title{Problem Set Week 7 Solutions}
\author{ETHZ Math Olympiad Club}
\date{7 April 2025}

\begin{document}
\maketitle
\problem[Problem A-2 (IMC 1999)]
Does there exist a bijective map \(\pi \colon \mathbb{N}_{>0} \to \mathbb{N}_{>0}\) such that
\[
\sum_{n=1}^{\infty} \frac{\pi(n)}{n^2} < \infty?
\]

\solution[Solutions:]
\textit{Solution 1.}
\\\\
No. For a very quick and clever solution, if we let \(\pi\) be a permutation of \(\mathbb{N}_{>0}\) and let \(N \in \mathbb{N}\), we shall argue that
\[
\sum_{n=N+1}^{3N} \frac{\pi(n)}{n^2} > \frac{1}{9}.
\]
In fact, of the \(2N\) numbers \(\pi\left[\llbracket N+1;3N\rrbracket\right]=\left\{\pi(N+1), \ldots, \pi(3N)\right\}\), only \(N\) can be smaller than or equal to \(N\), so at least \(N\) of them must be strictly bigger than \(N\). Hence,
\[
\sum_{n=N+1}^{3N} \frac{\pi(n)}{n^2} \geq \frac{1}{(3N)^2} \sum_{n=N+1}^{3N} \pi(n) \geq \frac{1}{9N^2} \cdot N \cdot N = \frac{1}{9}.
\]
The result follows directly because we have the infinite decomposition \(\mathbb{N}_{>0}= \bigsqcup_{N\in 3\mathbb{N}} \llbracket N+1;3N \rrbracket\).
\\\\
\textit{Alternative solutions.} There are two more solutions, both of which use the following fact:
\\\\
Let \(\pi\) be a permutation of \(\mathbb{N}^{*}\). Fix \(N \in \mathbb{N}^{*}\): the set of numbers \(\pi\left[\llbracket 1;N \rrbracket\right] = \left\{\pi(1), \ldots, \pi(N)\right\}\) is of size \(N\), i.e., the numbers are distinct positive integers. Thus, it is easy to prove\footnote{For the case \(N=1\), take \(\iota_1 = \mathrm{id}_{\llbracket 1;1 \rrbracket}\). The condition holds vacuously as \(\llbracket 1;N-1 \rrbracket = \varnothing\).
\\\\
Now assume the result holds for \(N \geq 1\). We prove it for \(N+1\). By the inductive hypothesis, there exists a permutation \(\iota_N \colon \llbracket 1;N \rrbracket \hookrightarrow \llbracket 1;N \rrbracket\) such that \(\pi\left(\iota_N(i+1)\right) > \pi\left(\iota_N(i)\right)\) for all \(i \in \llbracket 1;N-1 \rrbracket\). If \(\pi(N+1) > \pi\left(\iota_N(N)\right)\), define \(\iota_{N+1} = \iota_N \cup \left\{(N+1, N+1)\right\}\). This extends \(\iota_N\) to \(\llbracket 1;N+1 \rrbracket\) while preserving the order, so the result holds. Else, by injectivity, equality is impossible, so \(\pi(N+1) < \pi\left(\iota_N(N)\right)\), and hence we can take \(k\) to be the smallest index in \(\llbracket 1;N \rrbracket\) such that \(\pi(N+1) < \pi\left(\iota_N(k)\right)\). Define:
\[
\iota_{N+1} = \iota_N|_{\llbracket1;k-1\rrbracket} \cup \left\{(k, N+1)\right\} \cup \left\{(t+1, \iota_N(t))\,\middle|\, t \in \llbracket k;N \rrbracket\right\}.
\]
This changes the value at \(k\) to \(N+1\) and shifts the rest to take the preceding value. Clearly, \(\iota_N\) is a bijection, and \(\iota_{N+1}|_{\llbracket1;k-1\rrbracket}\) preserves the order. By choice of \(k\), \(\pi\left(\iota_{N+1}(k)\right) = \pi(N+1) < \pi\left(\iota_N(k)\right) = \pi\left(\iota_{N+1}(k+1)\right)\). Now if \(k > 1\), then by minimality (and again by injectivity), we have \(\pi\left(\iota_{N+1}(k)\right) = \pi(N+1) > \pi\left(\iota_N(k-1)\right) = \pi\left(\iota_{N+1}(k-1)\right)\). In all cases, \(\iota_{N+1}|_{\llbracket1;k+1\rrbracket}\) preserves the order. For \(N \geq i > k\), we have \(\pi\left(\iota_{N+1}(i+1)\right) = \pi\left(\iota_N(i)\right) > \pi\left(\iota_N(i-1)\right) = \pi\left(\iota_{N+1}(i)\right)\) by the inductive hypothesis. In total, \(\iota_{N+1}\) satisfies the required ordering. This concludes the induction step and hence the induction.} by induction over \(\mathbb{N}^{*}\) that there exists a permutation \(\iota_N \colon \llbracket 1;N \rrbracket \hookrightarrow \llbracket 1;N \rrbracket\) such that:
\[
\forall i \in \llbracket 1;N-1 \rrbracket,\quad \pi\left(\iota_N(i+1)\right) > \pi\left(\iota_N(i)\right).
\]
\textit{Solution 2.}
\\\\
Fix \(N \geq 1\). From our proposition above, it follows that there is a permutation of \(\llbracket 1;N \rrbracket\) such that for all \(t \in \llbracket 1;N-1 \rrbracket\), \(\pi\left(\iota_N(t+1)\right) > \pi\left(\iota_N(t)\right)\). In particular, since \(\pi\left(\iota_N(1)\right) \geq 1\), we get trivially by induction that for all \(t \in \llbracket 1;N \rrbracket\), \(\pi\left(\iota_N(t)\right) \geq t\), so that:
\[
\sum_{i=1}^{N} \pi(i) = \sum_{i=1}^{N} \pi\left(\iota_N(i)\right) \geq \sum_{i=1}^{N} i = \frac{N(N+1)}{2},
\]
and this holds for all \(N \in \mathbb{N}^{*}\). Now we perform the very useful-to-know \href{https://en.wikipedia.org/wiki/Summation_by_parts}{Abel transformation} on the finite sequences \(\pi|_{\llbracket 1; N \rrbracket}\) and \(\left(\frac{1}{n^2}\right)_{1 \leq n \leq N}\) to obtain:
\[
\sum_{n=1}^{N} \frac{\pi(n)}{n^2} = \frac{1}{N^2} \left(\sum_{n=1}^{N} \pi(n)\right) + \sum_{n=1}^{N-1} \left(\sum_{j=1}^{n} \pi(j)\right) \left( \frac{1}{n^2} - \frac{1}{(n+1)^2} \right)
\]
\[
\geq \sum_{n=1}^{N-1} \left( \frac{n(n+1)}{2} \right) \left( \frac{1}{n^2} - \frac{1}{(n+1)^2} \right) = \sum_{n=1}^{N-1} \frac{2n+1}{2n(n+1)} \geq \sum_{n=1}^{N-1} \frac{1}{n+1} = \sum_{n=2}^{N} \frac{1}{n}.
\]
Thus,
\[
\liminf_{N \to +\infty} \sum_{n=1}^{N} \frac{\pi(n)}{n^2} \geq \liminf_{N \to +\infty} \sum_{n=2}^{N} \frac{1}{n} = +\infty.
\]
\textit{Solution 3.}
\\\\
Fix \(N \geq 1\). Again, from our proposition, there is a permutation of \(\llbracket 1;N \rrbracket\) such that for all \(t \in \llbracket 1;N-1 \rrbracket\), \(\pi\left(\iota_N(t+1)\right) > \pi\left(\iota_N(t)\right)\). We are in the following situation:
\[
\frac{1}{N^2} \leq \cdots \leq \frac{1}{1^2}
\]
\[
\pi\left(\iota_N(1)\right) \leq \cdots \leq \pi\left(\iota_N(N)\right)
\]
By the very useful-to-know \href{https://en.wikipedia.org/wiki/Rearrangement_inequality}{rearrangement inequality}, we obtain:
\[
\sum_{n=1}^{N} \frac{\pi(n)}{n^2} \geq \sum_{n=1}^{N} \frac{\pi\left(\iota_N(n)\right)}{n^2}.
\]
Since \(\pi\left(\iota_N(1)\right) \geq 1\), we get trivially by induction that \(\pi\left(\iota_N(t)\right) \geq t\), so that:
\[
\sum_{n=1}^{N} \frac{\pi\left(\iota_N(n)\right)}{n^2} \geq \sum_{n=1}^{N} \frac{n}{n^2} = \sum_{n=1}^{N} \frac{1}{n}.
\]
Thus,
\[
\sum_{n=1}^{N} \frac{\pi(n)}{n^2} \geq \sum_{n=1}^{N} \frac{1}{n}.
\]
In particular, as \(N\) was arbitrary, we get:
\[
\liminf_{N \to +\infty} \sum_{n=1}^{N} \frac{\pi(n)}{n^2} \geq \liminf_{N \to +\infty} \sum_{n=2}^{N} \frac{1}{n} = +\infty.
\]
\newpage
\problem[Problem 2 (IMC 1994)]
Let \( f \in C^1\left( \left]a, b\right[, \mathbb{R} \right) \) with \( \lim_{x \to a^+} f(x) = +\infty \), \( \lim_{x \to b^-} f(x) = -\infty \), and  
\( f'(x) + f^2(x) \geq -1 \) for all \( x \in \left]a, b\right[ \). Prove that \( b - a \geq \pi \) and give an example where \( b - a = \pi \).

\solution[Solution:]
From the inequality, we obtain:
\[
\frac{\mathrm{d}}{\mathrm{d}x} \left( \arctan(f(x)) + x \right) = \frac{f'(x)}{1 + f^2(x)} + 1 \geq 0
\]
for all \( x \in \left]a, b\right[ \). Therefore, the function \( \arctan(f(x)) + x \) is non-decreasing on \( \left]a, b\right[ \). Taking limits as \( x \) approaches the endpoints, we get:
\[
\lim_{x\underset{>}{\to} a} \left( \arctan(f(x)) + x \right) = \frac{\pi}{2} + a, \quad \lim_{x\underset{<}{\to} b} \left( \arctan(f(x)) + x \right) = -\frac{\pi}{2} + b.
\]
Hence,
\[
\frac{\pi}{2} + a \leq -\frac{\pi}{2} + b,
\]
which implies \( b - a \geq \pi \).
\\\\
Equality is achieved when:
\[
f(x) = \cot(x) = \frac{\cos(x)}{\sin(x)}, \quad a = 0, \quad b = \pi,
\]
since for any \( x \in \left]0, \pi\right[ \), we have:
\[
f'(x) + f^2(x) = -\frac{1}{\sin^2(x)} + \frac{\cos^2(x)}{\sin^2(x)} = -\frac{\sin^2(x)}{\sin^2(x)} = -1,
\]
and the boundary conditions are satisfied:
\[
\lim_{x \underset{>}{\to} 0^+} \cot(x) = +\infty, \quad \lim_{ x\underset{<}{\to} \pi} \cot(x) = -\infty.
\]

\newpage
\problem[Problem B-3 (IMC 2005)]
In the linear space of all real \( n \times n \) matrices, find the maximum possible \( \mathbb{R} \)-dimension of an \( \mathbb{R} \)-linear subspace \( V \) such that
\[
    \forall X, Y \in V, \quad \operatorname{tr}\left(XY\right) = 0.
\]
(The trace of a matrix is the sum of its diagonal entries.)

\solution[Solution:]
For \( \left\{ \mathbf{0}_{n \times n} \right\} \), we have
\[
    \operatorname{tr}\left( \mathbf{0}_{n \times n} \cdot \mathbf{0}_{n \times n} \right) = \operatorname{tr}\left( \mathbf{0}_{n \times n} \right) = 0,
\]
so it is clear that an \( \mathbb{R} \)-subspace satisfying the condition exists. Denote by \( V \) such a subspace with the maximum possible \( \mathbb{R} \)-dimension (necessarily less than \( n^2 \)).
\\\\
Now, if \( A \) is a symmetric matrix, then:
\[
    \operatorname{tr}\left( A^2 \right) = \operatorname{tr}\left( A^T A \right)
    = \sum_{i=0}^{n-1} \left( A^T A \right)_{ii}
    = \sum_{i=0}^{n-1} \sum_{j=0}^{n-1} \left( A^T \right)_{ij} A_{ji}
    = \sum_{i=0}^{n-1} \sum_{j=0}^{n-1} \left( A_{ji} \right)^2
    = \left\| A \right\|_{F}^2,
\]
which is the sum of the squared entries of \( A \) (the Frobenius norm squared), and is strictly positive as long as \( A \neq \mathbf{0}_{n \times n} \). Therefore, \( V \) cannot contain any symmetric matrix except \( \mathbf{0}_{n \times n} \).
\\\\
Denote by \( S \) the \( \mathbb{R} \)-linear space of all real \( n \times n \) symmetric matrices; its \( \mathbb{R} \)-dimension is clearly \( \frac{n(n+1)}{2} \).  
Since \( V \cap S = \left\{ \mathbf{0}_{n \times n} \right\} \), we have
\[
    \dim_{\mathbb{R}}\left( V \right) + \dim_{\mathbb{R}}\left( S \right) \leq n^2,
\]
which gives
\[
    \dim_{\mathbb{R}}\left( V \right) \leq n^2 - \frac{n(n+1)}{2} = \frac{n(n-1)}{2}.
\]
Thus, the maximum \( \mathbb{R} \)-dimension is bounded above by \( \frac{n(n-1)}{2} \). This bound is tight: the space of strictly upper triangular matrices clearly has \( \mathbb{R} \)-dimension \( \frac{n(n-1)}{2} \) and satisfies the given condition.
\\\\
Therefore, the maximum \( \mathbb{R} \)-dimension of subspaces \( V \) satisfying the given condition is \( \frac{n(n-1)}{2} \).

\newpage
 
\problem[Problem 4 (Bernoulli Competition 2024)] 
Let \( n, m \in \mathbb{N}_{>0} \) be positive integers, with \( m \geq 3 \), and let \( A \in \mathbb{Z}^{n \times n} \). Suppose \( A \) has finite order (\( \exists k \in \mathbb{N}^{*},\, A^k = I_n \)) and satisfies
\[
A \equiv I_n \pmod{m} \footnote{For an integer \( u \in \mathbb{Z} \), \( \equiv \pmod{u} \) is the equivalence relation on the set of integer matrices \( \bigcup_{r,l \in \mathbb{N}^{*}} \mathbb{Z}^{r \times l} \), where for \( C, D \in \mathbb{Z}^{r \times l} \), \( C \equiv D \pmod{u} \Leftrightarrow \forall \left(i,j\right) \in r \times l,\, u \mid \left(C - D\right)\left(i,j\right) \).}.
\]
Prove that \( A = I_n \), and find counterexamples when \( m = 2 \).

\solution[Solutions:]
\textit{Solution 1.}
\\\\
Since \( A \equiv I_n \pmod{m} \), there exists \( B \in \mathbb{Z}^{n \times n} \) such that \( A = I_n + mB \). Then we have the following equality of characteristic polynomials:
\[
P_{\text{char},A}(X) = {\det}_{\mathbb{Q}(X)}\left(XI_n - A\right) = {\det}_{\mathbb{Q}(X)}\left(\left(X - 1\right)I_n - mB\right) = P_{\text{char},mB}\left(X - 1\right).
\]
Therefore, \( \alpha \in \mathbb{C} \) is an eigenvalue of \( A \) if and only if \( \alpha - 1 \) is an eigenvalue of \( mB \); that is, if and only if \( \frac{\alpha - 1}{m} \) is an eigenvalue of \( B \).
\\\\
Since \( \exists k \in \mathbb{N}_{>0}\) with \(A^k = I_n \), any eigenvalue \( \alpha \in \mathbb{C} \) of \( A \) satisfies \( \alpha^k = 1 \); thus, they are \( k \)-th roots of unity and lie on the unit circle \( \mathbb{S}^{1} \), i.e., \( \left|\alpha\right| = 1 \). Any eigenvalue \( \beta \in \mathbb{C} \) of \( B \) then satisfies (here \( m \geq 3 \) is crucial):
\[
\left|\beta\right| = \left| \frac{\alpha - 1}{m} \right| \leq \frac{\left|\alpha\right| + 1}{m} = \frac{2}{m} < 1.
\]
Now we prove that \( 0 \) is the only eigenvalue of \( B \)
\\\\
From this point, there are multiple ways to proceed; we present two approaches here.
\\\\
\textit{Intermediate step using Vieta’s formula.}
\\\\
Since \( \mathbb{Z} \) is a unique factorisation domain (UFD), so is \( \mathbb{Z}[X] \), and we can factor the characteristic polynomial of \( B \) (which is of degree \( n \geq 1 \)), \( P_{\text{char},B}(X) := \det_{\mathbb{Q}(X)}\left(XI_n - B\right) \in \mathbb{Z}[X] \), as a product of \( l \in \mathbb{N}^{*} \) unique irreducible polynomials (up to invertible element here these are $\pm1$). Since \( P_{\text{char},B}(X) \) is monic, the irreducible polynomials must have leading coefficients in \( \mathbb{Z}^{\times} = \left\{\pm 1\right\} \). Therefore, they must have degree at least one and cannot be irreducible elements of \( \mathbb{Z} \subset \mathbb{Z}[X] \)—namely, the primes up to sign. Hence, we may assume them to be monic (by multiplying, \textit{ubi opus est}, by \( -1 \)). That is,
\[
\exists \left\{P_i(X) \mid \forall i \in l,\, P_i(X) \text{ is irreducible and monic} \right\} \subset \mathbb{Z}_{\text{irr}}[X] \setminus \mathbb{Z}
\]
such that
\[
P_{\text{char},B}(X) = \prod_{i \in l} P_i(X).
\]
Now, let \( \beta \) be an eigenvalue of \( B \), i.e., \( \beta \in \mathrm{Root}_{P_{\text{char},B}(X)}\left(\mathbb{C}\right) \). Hence, there exists \( j \in l \) such that \( \beta \in \mathrm{Root}_{P_j(X)}\left(\mathbb{C}\right) \). For a certain \( s_j \in \mathbb{N}_{>0} \) and distinct complex numbers \( \left\{\,_{j}\beta_i \mid i \in s_j \right\} \subset \mathbb{C} \), we have
\[
\mathrm{Root}_{P_j(X)}\left(\mathbb{C}\right) = \left\{\,_{j}\beta_i \mid i \in s_j \right\}.
\]
As we have seen above,
\[
\mathrm{Root}_{P_{\text{char},B}(X)}\left(\mathbb{C}\right) \subset \mathbb{D},
\]
so \( \left\{\,_{j}\beta_i \mid i \in s_j \right\} \subset \mathbb{D} \).
However, since these are the roots of \( P_j(X) \), we must have, by Vieta’s formula, that their product equals (up to a sign) the constant term of \( P_j(X) \):
\[
\prod_{i\in s_j} \,_{j}\beta_i = \pm P_j\left(0\right).
\]
Then
\[
\left|P_j\left(0\right)\right| = \left| \prod_{i\in s_j} \,_{j}\beta_i \right| = \prod_{i\in s_j} \left| \,_{j}\beta_i \right| < 1.
\]
Since \( P_{j}(X) \in \mathbb{Z}\left[X\right] \), we must have \( P_j\left(0\right) \in \mathbb{Z} \), and because \( \left|P_j\left(0\right)\right| < 1 \) we must have \( P_j\left(0\right) = 0 \). Therefore, \( 0 \) is a root of \( P_j \), and thus \( X \) divides \( P_j(X) \) in \( \mathbb{Z}\left[X\right] \). Since \( P_j(X) \) has degree at least \( 1 \) and is irreducible in \( \mathbb{Z}\left[X\right] \), this cannot happen unless \( P_j(X) \) has degree \( 1 \). So \( P_j(X) = kX \) for a certain \( k \in \mathbb{Z} \setminus \left\{0\right\} \). Since \( P_j(X) \) is monic, \( k = 1 \), and we conclude \( P_j(X) = X \). Hence \( \beta = 0 \), since it is a root of \( P_j(X) \) by choice of \( j \). As $\beta\in\sigma(B)$ was arbitrary we conclude $\sigma(B)=\{0\}$ as desired.
\\\\
\textit{Alternative proof of intermediate step using Newton’s identities.}
\\\\
Fix \( m \in \mathbb{N}_{>0} \). For \( k \in \mathbb{N} \), let the \(k\)-th power sum polynomials in \( m \) variables
\[
p_k\left(\mathbf{X}\right) := \sum_{i \in m} X_i^k \in \mathbb{Z}\left[\mathbf{X}\right],
\]
and the \(k\)-th elementary symmetric polynomials in \(m\)
\[
e_k\left(\mathbf{X}\right) := \sum_{\substack{A \in \mathscr{P}(m)\\\left|A\right| = k}} \prod_{a \in A} X_a \in \mathbb{Z}\left[\mathbf{X}\right]\footnote{That is:
\[
e_0\left(\mathbf{X}\right) = 1,\, e_1\left(\mathbf{X}\right) = \sum_{i \in m} X_i,\, e_2\left(\mathbf{X}\right) = \sum_{0 \leq i < j < m} X_i X_j,\, \ldots,\, e_n\left(\mathbf{X}\right) = \prod_{i \in m} X_i,
\]
and \( e_k\left(\mathbf{X}\right) = 0 \) for \( k > m \).}.
\]
The \href{https://en.wikipedia.org/wiki/Newton%27s_identities}{Newton’s identities} relate these polynomials by the identity (valid for \( m \geq k \geq 1 \)):
\[
k e_k\left(\mathbf{X}\right) = \sum_{i=1}^k (-1)^{i-1} e_{k-i}\left(\mathbf{X}\right) p_i\left(\mathbf{X}\right).
\]
For a short combinatorial proof of these identities, see the Appendix [\hyperref[A1]{A.1}].
As shown earlier, all eigenvalues of \( B \) lie inside the unit disc: \( \mathrm{Root}_{P_{\text{char},B}(X)}\left(\mathbb{C}\right) \subset \mathbb{D} \). Let \( \boldsymbol{\beta} \in \mathbb{D}^n \) be the vector of eigenvalues of \( B \), counted with multiplicity, so that \( \sigma(B) = \mathrm{Root}_{P_{\text{char},B}(X)}\left(\mathbb{C}\right) = \left\{ \beta_i \mid i \in n \right\} \). In our case, where the number of variables is \( n \geq 1 \), we define, for all \( k \geq 0 \), the \( k \)-th power sum and the \( k \)-th elementary symmetric polynomial in the eigenvalues of \( B \), respectively:
\[
p_k := p_k\left(\boldsymbol{\beta}\right) = \sum_{i \in n} \beta_i^k,\quad e_k := e_k\left(\boldsymbol{\beta}\right) = \sum_{\substack{A \in \mathscr{P}(n)\\\left|A\right| = k}} \prod_{a \in A} \beta_a.
\]
Note that \( p_k = \operatorname{tr}\left(B^k\right) \), and \( e_k = c_{n-k}\left(P_{\text{char},B}(X)\right) \). Since \( B \in \mathbb{Z}^{n \times n} \), we have \( p_k \in \mathbb{Z} \) and \( e_k \in \mathbb{Z} \).
\\\\
Let \( \gamma \in \sigma(B) \) be an eigenvalue of \( B \). Since \( \left|\gamma\right| < 1 \), we have \( \gamma^N \overset{N \to +\infty}{\longrightarrow} 0 \). Therefore, each term in the finite sum (comprising \( n \) summands) \( p_N \) tends to zero as \( N \to +\infty \); that is,
\[
p_N \overset{N \to +\infty}{\longrightarrow} 0.
\]
However, as mentioned earlier, for all \( N \in \mathbb{N} \), \( p_N \in \mathbb{Z} \), so there exists \( M \geq 0 \) such that for all \( N \geq M \), \( p_N = 0 \). We now show that this condition implies, surprisingly, that \( \boldsymbol{\beta} = \mathbf{0}_n \). For this, we denote by \( \boldsymbol{\beta}^M := \left( \beta_i^M \right)_{i \in n} \) the eigenvalues of \( B^M \), and we define, for all \( k \geq 0 \),
\[
\tilde{p}_k := p_k\left( \boldsymbol{\beta}^M \right) = \sum_{i \in n} \left( \beta_i^M \right)^k = p_{Mk}, \quad \tilde{e}_k := e_k\left( \boldsymbol{\beta}^M \right) = \sum_{\substack{A \in \mathscr{P}\left( n \right)\\\left|A\right| = k}} \prod_{a \in A} \beta_a^M.
\]
Notice that \( \tilde{e}_k = c_{n-k}\left( P_{\text{char},B^M}\left( X \right) \right) \).  
We prove by induction that for \( k \geq 1 \), we have \( \tilde{e}_k = 0 \).  
\begin{itemize}
\item For \( k = 1 \), \( \tilde{e}_1 = \tilde{p}_1 = p_M = 0 \).
\item Let \( k \geq 1 \) and assume that for all \( j \) with \( 1 \leq j \leq k - 1 \), we have \( \tilde{e}_j = 0 \). Then Newton's identities give
\[
k \tilde{e}_k = (-1)^{k-1} \tilde{e}_0 \tilde{p}_k = (-1)^{k-1} \tilde{p}_k = (-1)^{k-1} p_{Mk}.
\]
As \( Mk \geq M \), we have \( p_{Mk} = 0 \), so \( k \tilde{e}_k = 0 \), and since \( k \neq 0 \), it follows that \( \tilde{e}_k = 0 \).
\end{itemize}
This implies that the characteristic polynomial of \( B^M \) is \( X^n \), meaning all eigenvalues of \( B^M \) are zero; that is, \( \boldsymbol{\beta}^M = \mathbf{0}_n \), and hence \( \boldsymbol{\beta} = \mathbf{0}_n \)\footnote{In fact, we have just proved a curious result: if we have \( \boldsymbol{\lambda} \in \mathbb{C}^n \) such that there exists some \( M \in \mathbb{N} \) for which, for all \( N \geq M \), we have \( p_N\left( \boldsymbol{\lambda} \right) = 0 \), then it follows that \( \boldsymbol{\lambda} = \mathbf{0}_n \). Indeed, one may either take the \href{https://en.wikipedia.org/wiki/Companion_matrix}{companion matrix} of the monic polynomial \( \prod_{i \in n} \left( X - \lambda_i \right) \)—that is, the matrix whose characteristic polynomial is this one—and proceed as we have just done, or, without speaking of matrices at all, define for all \( k \geq 0 \) the elements \( \hat{e}_k := e_k\left( \lambda^M \right) \), and prove by induction, as above, that each of them (starting from \( 1 \)) is zero. Then perform a descending induction: \( 0 = \hat{e}_n = \prod_{i \in n} \lambda_i^M \), hence there is an \( i_0 \in n \) with \( \lambda_{i_0} = 0 \). Now remove \( \lambda_{i_0} \) from the set \( \left\{ \lambda_i \mid i \in n \right\} \), obtaining a smaller set of size \(n'\). If it is empty ($n'=0$) then $\boldsymbol{\lambda}=\mathbf{0}_{n}$, else we consider the vector \( \boldsymbol{\lambda}'\in\mathbb{C}^{n'} \) consisting of the remaining elements. Again, it is clear that for all \( N \geq M \), each \( p_N\left( \boldsymbol{\lambda}' \right) = 0 \) (where the \( N \)-th power sum polynomials are in \(n'\) variables); their \( k \)-th elementary symmetric sums in \(\left(\boldsymbol{\lambda}'\right)^{M}\) must again vanish (starting from \( k = 1 \) and applying the same induction), so $e_{n'}\left(\left(\boldsymbol{\lambda}'\right)^{M}\right)=0$ and there is $i_1\in n$ such that \( \lambda_{i_1} \in \left\{ \lambda_i \mid i \in n \right\} \setminus \left\{ \lambda_{i_0} \right\} \) is \( 0 \). Continue this process until the entire set is exhausted. The advantage of the latter procedure is that we can, in fact, apply it to any integral ring \( R \) of characteristic \( 0 \), since it then canonically contains \( \mathbb{Z} \hookrightarrow R \), and thus the Newton identities hold on $R$.
}.
\\\\
This concludes the two different approaches to show that \( \sigma\left( B \right) = \left\{ 0 \right\} \). We can now quickly finish the problem. All the eigenvalues of \( B \) are \( 0 \); this is clearly equivalent to \( P_{\text{char},B}\left( X \right) = X^n \). According to the Cayley-Hamilton theorem, \( B^n = \mathbf{0}_{n\times n} \), so \( B \) is nilpotent and thus \( mB \) is nilpotent. Now, use the following
\begin{lemma}
Let $K$ be a field of characteristic $\operatorname{char}(K) = 0$, \( l \in \mathbb{N}_{>0} \), and \( N \in K^{l \times l} \) be a nilpotent matrix. If \( I_{l} + N \) has finite order, then \( N = \mathbf{0}_{l \times l} \).
\end{lemma}
The proof can be found in Appendix [\hyperref[A2]{A.2}].
\\\\
Apply this result to the field $\mathbb{Q}$ with \( n \geq 1 \); since \( mB \in \mathbb{Q}^{n \times n} \) is nilpotent and \( A = I_n + mB \) has finite order, we conclude that \( mB = \mathbf{0}_{n \times n} \), and so \( B = \mathbf{0}_{n \times n} \) (as \( m \in \mathbb{Q}^{\times} \)). Hence, \( A = I_n \), and this concludes the proof.

\newpage
\textit{Solution 2.}
\\\\
Assume for contradiction that \( A \neq I_n \). Since \( m \geq 3 \), \( m \) must be divisible by some prime power greater than 2, that is, there exists \( p \in \mathbb{P} \) a prime number and \( c \geq 1 \) such that \( p^c \mid m \) and \( p^c > 2 \) (if \( p = 2 \), then \( c \geq 2 \) necessarily). In particular, from \( A \equiv I_n \pmod{m} \), we must have \( A \equiv I_n \pmod{p^c} \).
\\\\
Since \( A \neq I_n \), there is \( (i,j) \in n \times n \) such that \( \left( A - I_n \right)(i,j) \neq 0 \), and so 
\[
c \leq v_p\left( \left( A - I_n \right)(i,j) \right) \neq +\infty,
\]
where \( v_p \colon \mathbb{Q} \rightarrow \mathbb{Z} \cup \left\{ +\infty \right\} \) denotes the \( p \)-adic valuation. We can thus let 
\[
c' := \min\left\{ v_p\left( \left( A - I_n \right)(i,j) \right) \,\middle\vert\, (i,j) \in n \times n \right\} \geq c.
\]
Then \( c' \in \mathbb{N}_{\geq c} \) is (by construction) the largest integer such that \( A \equiv I_n \pmod{p^{c'}} \). Consequently, we define 
\[
B := \frac{1}{p^{c'}} \left( A - I_n \right),
\]
for which (by definition of \( c' \)), \( B \in \mathbb{Z}^{n \times n} \) and \( B \not\equiv \mathbf{0}_{n \times n} \pmod{p} \).
\\
Since \( A \) has finite order, there exists \( k \in \mathbb{N}^{*} \) with \( A^k = I_n \); furthermore, \( k \geq 2 \) because \( A \neq I_n \). We want to expand:
\[
I_n = A^k = \left( I_n + p^{c'} B \right)^k.
\]
This can be done (happily) by the binomial theorem since \( I_n \) and \( p^{c'} B \) commute, and we obtain:
\[
I_n = \sum_{i=0}^{k} \binom{k}{i} p^{i c'} B^i.
\]
This implies:
\[
\sum_{i=1}^{k} \binom{k}{i} p^{i c'} B^i = \mathbf{0}_{n \times n},
\]
or equivalently (since \( k \geq 2 \)), we obtain the equation:
\[
\sum_{i=2}^{k} \binom{k}{i} p^{i c'} B^i = -k p^{c'} B.
\]
We shall show that this leads to a contradiction. Let \( c'' := v_p(k) \geq 0 \). We prove:
\begin{equation}
-k p^{c'} B \not\equiv \mathbf{0}_{n \times n} \pmod{p^{c' + c'' + 1}},
\end{equation}
\label{1}
whilst
\begin{equation}
\sum_{i=2}^{k} \binom{k}{i} p^{i c'} B^i \equiv \mathbf{0}_{n \times n} \pmod{p^{c' + c'' + 1}},
\end{equation}
\label{2}
which is impossible by the derived equation above.
\\
For (\hyperref[1]{1}): because \( v_p\left( k p^{c'} \right) = c' + c'' \) and \( B \not\equiv \mathbf{0}_{n \times n} \pmod{p} \), we have \( -k p^{c'} B \not\equiv \mathbf{0}_{n \times n} \pmod{p^{c' + c'' + 1}} \) (but obviously \( k p^{c'} B \equiv \mathbf{0}_{n \times n} \pmod{p^{c' + c''}} \)).
\\
For (\hyperref[2]{2}): let \( 2 \leq i \leq k \), note that \( i! \binom{k}{i} = \frac{k!}{(k-i)!} \) is divisible by \( k \), hence by \( p^{c''} \), whilst the largest power of \( p \) dividing \( i! \) is classically bounded above by the famous \href{https://en.wikipedia.org/wiki/Legendre%27s_formula}{Legendre's formula}\footnote{A quick proof of this formula for \( p \in \mathbb{P} \) and \( i \geq 1 \) proceeds as follows: define \( M := \max\left\{ v_{p}(t) \,\middle\vert\, 1 \leq t \leq i \right\} \), then:
$$
v_p(i!) = \sum_{t=1}^{i} v_p(t) = \sum_{t=1}^{i} \left( \sum_{\substack{j=1 \\ p^j \mid_{\mathbb{Z}} t}}^{M} 1 \right) = \sum_{\substack{(t,j) \in \left\llbracket 1, i \right\rrbracket \times \left\llbracket 1, M \right\rrbracket \\ p^{j} \mid_{\mathbb{Z}} t}} 1 = \sum_{j=1}^{M} \left( \sum_{\substack{t=1 \\ p^j \mid_{\mathbb{Z}} t}}^{i} 1 \right) = \sum_{j=1}^{M} \left\lvert \left\{ t \in \left\llbracket 1, i \right\rrbracket \,\middle\vert\, p^j \mid_{\mathbb{Z}} t \right\} \right\rvert
$$
$$
= \sum_{j=1}^{M} \left\lvert \left\{ p^j s \leq i \,\middle\vert\, s \in \mathbb{N}_{>0} \right\} \right\rvert = \sum_{j=1}^{M} \left\lvert \left\{ s \in \mathbb{N}_{>0} \,\middle\vert\, p^j s \leq i \right\} \right\rvert = \sum_{j=1}^{M} \left\lfloor \frac{i}{p^j} \right\rfloor = \sum_{j=1}^{+\infty} \left\lfloor \frac{i}{p^j} \right\rfloor.
$$
Here, we use the total multiplicativity of \( v_p \) for the first equality; the interchange of sums is justified by their finiteness. The final equality follows from the definition of \( M \), since if \( j \in \mathbb{N} \) is such that \( j > M \), then \( j > v_p(i) \), hence \( \frac{i}{p^{j}} < 1 \), and thus \( \left\lfloor \frac{i}{p^{j}} \right\rfloor = 0 \). The remaining equalities follow from elementary counting.}:
\[
v_p(i!) = \sum_{j=1}^{+\infty} \left\lfloor \frac{i}{p^j} \right\rfloor < \sum_{j=1}^{+\infty} \frac{i}{p^j} = \frac{i}{p - 1}.
\]
We claim that \( v_p(i!) \leq \left\lfloor \frac{i-1}{p-1} \right\rfloor \). Assume for the sake of contradiction that \( \left\lfloor \frac{i-1}{p-1} \right\rfloor < v_p(i!) \). Since both are integers, \( \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \leq v_p(i!) \). As \( v_p(i!) < \frac{i}{p-1} \) and \( i \geq 2 \Rightarrow \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \geq 1 \), we obtain:
\[
\left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 < \frac{i}{p-1} \Rightarrow (p-1)\left( \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \right) < i.
\]
Again, since \( i, (p-1)\left( \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \right) \) are integers, we have:
\[
(p-1)\left( \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \right) + 1 \leq i.
\]
However, by definition of the floor function:
\[
\frac{i-1}{p-1} < \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \Rightarrow i < (p-1)\left( \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \right) + 1.
\]
Combining:
\[
i < (p-1)\left( \left\lfloor \frac{i-1}{p-1} \right\rfloor + 1 \right) + 1 \leq i,
\]
that is, \( i < i \), a contradiction. Thus, \( v_p(i!) \leq \left\lfloor \frac{i-1}{p-1} \right\rfloor \). So:
\[
v_p\left( \binom{k}{i} p^{i c'} \right) = v_p\left( \frac{i! \binom{k}{i}}{i!} p^{i c'} \right) = v_p\left( p^{i c'} \right) + v_p\left( i! \binom{k}{i} \right) - v_p(i!) \geq i c' + c'' - \left\lfloor \frac{i-1}{p-1} \right\rfloor.
\]
If \( p = 2 \), then \( c' \geq c \geq 2 \) and \( \frac{i-1}{p-1} = i - 1 \), so:
\[
i c' + c'' - \left\lfloor \frac{i-1}{p-1} \right\rfloor = i(c' - 1) + c'' + 1
\]
\[\geq 2(c' - 1) + c'' + 1 = c' + c'' + (c' - 2) + 1 \geq c' + c'' + 1.
\]
If \( p \geq 3 \), then \( \frac{i-1}{p-1} \leq \frac{i-1}{2} \), so that \( \left\lfloor \frac{i-1}{p-1} \right\rfloor \leq \left\lfloor \frac{i-1}{2} \right\rfloor \), and thus:
\[
i c' + c'' - \left\lfloor \frac{i-1}{p-1} \right\rfloor \geq i c' + c'' - \left\lfloor \frac{i-1}{2} \right\rfloor
\]
\[= c' + c'' + (i - 1)c' - \left\lfloor \frac{i-1}{2} \right\rfloor \geq c' + c'' + (i - 1) - \left\lfloor \frac{i-1}{2} \right\rfloor
\]
\[= c' + c'' + \left\lceil \frac{i-1}{2} \right\rceil \geq c' + c'' + 1,
\]
where we used the fact that for an integer \( r \in \mathbb{Z} \), we have \( r - \left\lfloor \frac{r}{2} \right\rfloor = \left\lceil \frac{r}{2} \right\rceil \) (for this equality, break \( r \) into two cases based on its parity: \( 2t \) or \( 2t + 1 \)) and that \( i - 1 > 0 \).
\\
In all cases for $p$:
\[
v_p\left( \binom{k}{i} p^{i c'} \right) \geq c' + c'' + 1,
\]
and so \( p^{c' + c'' + 1} \) divides \( \binom{k}{i} p^{i c'} \). As $2\leq i\leq k$ was arbitrary, we get that:
\[
\sum_{i=2}^{k} \binom{k}{i} p^{i c'} B^i \equiv \mathbf{0}_{n \times n} \pmod{p^{c' + c'' + 1}}.
\]
This shows our desired contradiction. Thus, our initial assumption must be false and \( A = I_n \). This concludes the proof.
\\\\
Counterexamples for general $n\geq 1$ is easy to find for example $-I_n$. If we want to find one that is not a diagonal matrix, we split the case between even and odd dimension. When $n=2k>0$ we place \( k \) copies of a \( 2 \times 2 \) counterexamples block (which satisfies the condition) along the diagonal, when $n=2k+1>0$  we place \( k \) copies of the same \( 2 \times 2 \) block and a final $\pm1$ on the diagonal
\[
\begin{pmatrix}
1 & 2 & 0 & \cdots & 0 & 0 \\
0 & -1 & 0 & \cdots & 0 & 0 \\
0 & 0 & 1 & 2 & \cdots & 0 \\
0 & 0 & 0 & -1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & 0 & \cdots & \begin{matrix} 1 & 2 \\ 0 & -1 \end{matrix}
\end{pmatrix} \in \mathbb{Z}^{2k \times 2k},
\]
\[
\begin{pmatrix}
1 & 2 & 0 & \cdots & 0 & 0 & 0 \\
0 & -1 & 0 & \cdots & 0 & 0 & 0 \\
0 & 0 & 1 & 2 & \cdots & 0 & 0 \\
0 & 0 & 0 & -1 & \cdots & 0 & 0 \\
\vdots & \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\
0 & 0 & 0 & 0 & \cdots & \begin{matrix} 1 & 2 \\ 0 & -1 \end{matrix} & 0 \\
0 & 0 & 0 & 0 & \cdots & 0 & \pm 1
\end{pmatrix} \in \mathbb{Z}^{(2k+1) \times (2k+1)}.
\]
\appendix
\newpage
\section{}
\subsection{}\label{A1}
\begin{theorem}[Newton's Identities]
For positive integers \( m\geq k \geq 1 \), the following identity holds over the ring \( \mathbb{Z}[X_0,\ldots,X_{m-1}] = \mathbb{Z}[\mathbf{X}] \):
\[
k\left( \sum_{\substack{A \in \mathscr{P}(m) \\ \left|A\right| = k}} \prod_{a \in A} X_{a} \right)
- \sum_{i=1}^{k} (-1)^{i-1} \left( \sum_{\substack{A \in \mathscr{P}(m) \\ \left|A\right| = k-i}} \prod_{a \in A} X_{a} \right)
\left( \sum_{j \in m} X_j^{i} \right) = 0.
\]
\end{theorem}
The following short combinatorial proof is due to Doron Zeilberger (1983).
\begin{proof}
Alternatively, the identity can be rewritten as:
\[
0 = k\left( \sum_{\substack{A \in \mathscr{P}(m) \\ \left|A\right| = k}} \prod_{a \in A} X_{a} \right)
+ \sum_{i=1}^{k} (-1)^{i} \left( \sum_{\substack{A \in \mathscr{P}(m) \\ \left|A\right| = k-i}} \prod_{a \in A} X_{a} \right)
\left( \sum_{j \in m} X_j^{i} \right)
\]
\begin{equation}
\label{eq:star}
\tag{*}
= \left( \sum_{\substack{A \in \mathscr{P}(m) \\ \left|A\right| = k}} \sum_{j \in A} (-1)^{0}
\left( \prod_{a \in A} X_a \right) X_j^0 \right)
+ \left( \sum_{i=1}^{k} \sum_{\substack{A \in \mathscr{P}(m) \\ \left|A\right| = k-i}} \sum_{j \in m} (-1)^{i}
\left( \prod_{a \in A} X_a \right) X_j^i \right).
\end{equation}
We establish the identity by defining a sign-reversing involution on a combinatorial structure.
\\\\
Define the set of \( 3 \)-tuples:
\[
\mathcal{A}(n, k) := \left\{ \left\langle A, i, j \right\rangle \,\middle|\, 
\begin{array}{l}
A \in \mathscr{P}(m),\ |A| \leq k,\ j \in m,\ i = k - |A|,\ \\
\text{and if } i = 0 \text{ then } j \in A
\end{array}
\right\}.
\]
The \emph{weight} of \( \left\langle A, j, i \right\rangle \) is defined as:
\[
w\left( \left\langle A, j, i \right\rangle \right) := (-1)^{i} \left( \prod_{a \in A} X_a \right) X_j^i \in \mathbb{Z}[\mathbf{X}].
\]
The sum of the weights of all elements in \( \mathcal{A}(n, k) \) is readily seen to be equal to \hyperref[eq:star]{(*)}. To show this sum is zero, define the function \( T: \mathcal{A}(n, k) \to \mathcal{A}(n, k) \) as:
\[
T\left( \left\langle A, j, i \right\rangle \right) =
\begin{cases}
\left\langle A \setminus \left\{ j \right\}, j, i + 1 \right\rangle, & \text{if } j \in A, \\
\left\langle A \cup \left\{ j \right\}, j, i - 1 \right\rangle, & \text{if } j \notin A.
\end{cases}
\]
With a mental exercise, we see that \( T \) is well defined and satisfies:
\begin{itemize}
    \item \( w\left( T\left( \left\langle A, j, i \right\rangle \right) \right) = -w\left( \left\langle A, j, i \right\rangle \right) \),
    \item \( T \circ T = \mathrm{id}_{\mathcal{A}(n, k)} \).
\end{itemize}
Thus, every element \( \left\langle A, j, i \right\rangle \) uniquely pairs with its image under \( T \) (since it is an involution), and their weights cancel. Hence, the total sum is zero.
\end{proof}

\newpage
\subsection{}\label{A2}
\begin{lemma}
Let \( l \in \mathbb{N}_{>0} \) and \( R \) be a commutative unital ring together with the canonical morphism \( \operatorname{can}_{R}:\mathbb{Z} \rightarrow R \). Let \( N \in R^{l\times l} \) be a nilpotent matrix. If \( I_{l} + N \) has finite order \( r \in \mathbb{Z}_{>0} \) (where \( I_l \) is the identity matrix in \( R^{l\times l} \)) such that \( \operatorname{can}_{R}\left(r\right) \overset{not.}{=} r_{R} \in R^{\times} \) is invertible, then \( N = \mathbf{0}_{R^{l\times l}} \).
\end{lemma}

\begin{proof}
Let \( r := \operatorname{ord}_{R^{l\times l}}\left(I_{l} + N\right) \in \mathbb{Z}_{>0} \) be the order of \( I_{l} + N \). Then, by the binomial theorem (noting that \( I_{l} \) and \( N \) commute),
\[
I_l = \left(I_l + N\right)^r = \sum_{j=0}^{r} \binom{r}{j}_{R} N^{j} = I_l + \sum_{j=1}^{r} \binom{r}{j}_{R} N^{j},
\]
where the binomial coefficient is interpreted through the canonical morphism \( \operatorname{can}_{R}:\mathbb{Z} \rightarrow R \). It follows that
\[
\mathbf{0}_{R^{l\times l}} = \sum_{j=1}^{r} \binom{r}{j}_{R} N^{j},
\]
and because \( R \) is commutative, we can factor \( N \) to obtain:
\[
\mathbf{0}_{R^{l\times l}} = N \left( \sum_{j=1}^{r} \binom{r}{j}_{R} N^{j-1} \right) = N \left( r_{R} I_{l} + \sum_{j=2}^{r} \binom{r}{j}_{R} N^{j-1} \right).
\]
Let \( S := r_{R} I_{l} + \sum_{j=2}^{r} \binom{r}{j}_{R} N^{j-1} \in R^{l\times l} \) be the right-hand factor in this product, and define \( E := \sum_{j=2}^{r} \binom{r}{j}_{R} N^{j-1} \in R^{l\times l} \) (the sum is possibly empty if \( r = 1 \), in which case it is the empty sum and \( E = \mathbf{0}_{l\times l} \)). So \( S = r_{R} I_l + E \), and we claim that \( S \) is invertible.
\\\\
Indeed, \( N \) is nilpotent, and so are all of its powers. Since \( R \) is commutative, any scalar multiple \( \lambda N^k \) with \( \lambda \in R \) and \( k \in \mathbb{N}_{>0} \) is nilpotent. Moreover, for any (possibly non-commutative) unital ring \( A \) (here \( R^{l \times l} \)), the set of nilpotent elements \( \operatorname{Nil}\left( A \right) \) is closed\footnote{For the finite product, the index of nilpotency is bounded above by the minimum of the respective indices of nilpotency (use the commutativity of the factors). For the finite sum, the index of nilpotency is bounded above by 1 plus the sum of the nilpotency indices minus the number of summands. To see this, use the multinomial theorem (which is valid since the summands commute) and use the pigeon hole principle.} under finite sums and products, provided that the terms commute pairwise. Because \( R \) is commutative, we get that for any \( \lambda, \lambda' \in R \) and \( k, k' \in \mathbb{N}_{>0} \), the elements \( \lambda N^k \) and \( \lambda' N^{k'} \) commute. Hence \( E \in \operatorname{Nil}\left(R^{l\times l}\right) \).
\\\\
Now \( r_{R} \in R^{\times} \), so we must have \( r_{R} I_{l} \in \left(R^{l\times l}\right)^{\times} \). As \( E \) is nilpotent and \( E \) commutes with \( r_{R} I_{l} \) (since \( R \) is commutative), the element \( S := r_{R} I_{l} + E \), being the sum of an invertible element of \( R^{l\times l} \) and a nilpotent one, must be invertible\footnote{This is a general fact about any (possibly non-commutative) unital ring \( A \): if \( a \in A^{\times} \), \( b \in \operatorname{Nil}(A) \), and \( ab = ba \), then \( a + b \in A^{\times} \). Indeed, let \( v \in \mathbb{N}_{>0} \) be the index of nilpotency of \( b \). Then, since \( a \) and \( b \) commute, so do \( a^{-1} \) and \( b \), and we have \( \left(ba^{-1}\right)^v = b^va^{-v} = 0_{A} \). A simple computation (using the fact that \( \pm 1_{A} \) commutes with every element, and that \( a \), \( b \), and \( a^{-1} \) commute with one another, as do their powers) shows that the element
\[
a^{-1} \left( \sum_{k=0}^{v-1} \left(-1_{A}\right)^k \left(b a^{-1}\right)^k \right)\in A,
\]
is both a left and right inverse of \( a + b = a \left(1_{A} + a^{-1} b\right)=\left(1_{A} + ba^{-1}\right)a\), and so $a+b\in A^{\times}$}.
\\\\
Thus, multiplying by \( S^{-1} \) on both sides of the equation \( \mathbf{0}_{R^{l\times l}} = N S \) yields \( N = \mathbf{0}_{R^{l\times l}} \).
\end{proof}

\end{document}